# Transformer_Pruning
My goal is to adapt and understand open-source research on state-of-the-art(SOTA) Transformer compressing for my own research purposes.

ðŸ“¦ Implemented

**Pruning on MHA**: 
- CoFi
- DynaBERT

**Retraining Pruning**: 
- DynaBERT
- EBERT
